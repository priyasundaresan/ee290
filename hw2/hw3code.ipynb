{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "import pprint\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected Subgradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_projected_subgradient(A, y, x0, iters=20000):\n",
    "    m, n = A.shape\n",
    "    A_pseudo = A.T.dot(np.linalg.inv(A.dot(A.T)))\n",
    "    gamma = np.eye(n) - A_pseudo.dot(A)\n",
    "    print(np.isnan(gamma).any())\n",
    "    x_hat = A_pseudo.dot(y)\n",
    "    x = np.zeros(n)\n",
    "    for i in range(iters):\n",
    "        t = i+1\n",
    "        x = x_hat + gamma.dot(x - (np.sign(x)/t))\n",
    "        \n",
    "        \n",
    "        error = np.linalg.norm(A.dot(x) - y)\n",
    "        if t%1000 == 0:\n",
    "            print('[%d, %5d] loss: %.7f' % (t, iters, error))\n",
    "        if np.isnan(A.dot(x)).any():\n",
    "            print(np.isnan(np.sign(x)/t).any())\n",
    "            print(t, A, x)\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[1000, 20000] loss: 0.0000000\n",
      "[2000, 20000] loss: 0.0000000\n",
      "[3000, 20000] loss: 0.0000000\n",
      "[4000, 20000] loss: 0.0000000\n",
      "[5000, 20000] loss: 0.0000000\n",
      "[6000, 20000] loss: 0.0000000\n",
      "[7000, 20000] loss: 0.0000000\n",
      "[8000, 20000] loss: 0.0000000\n",
      "[9000, 20000] loss: 0.0000000\n",
      "[10000, 20000] loss: 0.0000000\n",
      "[11000, 20000] loss: 0.0000000\n",
      "[12000, 20000] loss: 0.0000000\n",
      "[13000, 20000] loss: 0.0000000\n",
      "[14000, 20000] loss: 0.0000000\n",
      "[15000, 20000] loss: 0.0000000\n",
      "[16000, 20000] loss: 0.0000000\n",
      "[17000, 20000] loss: 0.0000000\n",
      "[18000, 20000] loss: 0.0000000\n",
      "[19000, 20000] loss: 0.0000000\n",
      "[20000, 20000] loss: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "m = 100\n",
    "n = 200\n",
    "k = 0\n",
    "rank = 100\n",
    "rank_idxs = np.random.choice(m, m-rank)\n",
    "\n",
    "A = np.random.rand(m,n)\n",
    "u, s, vh = np.linalg.svd(A, full_matrices=True)\n",
    "s[rank_idxs] = 0\n",
    "smat = np.zeros((m, n))\n",
    "smat[:m, :m] = np.diag(s)\n",
    "A = np.dot(u, np.dot(smat, vh))\n",
    "\n",
    "x0 = np.random.rand(n)\n",
    "idxs = np.random.choice(n, k)\n",
    "x0[idxs] = 0\n",
    "\n",
    "y = A.dot(x0)\n",
    "\n",
    "x = run_projected_subgradient(A, y, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "189-hw",
   "language": "python",
   "name": "189-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
